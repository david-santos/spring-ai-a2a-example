spring.application.name=spring-ai-a2a-editor

server.port=8082

logging.level.pt.dcs.example.spring_ai.a2a.editor=DEBUG
logging.level.org.springaicommunity.a2a.server.executor=DEBUG

# Ollama chat model
# https://huggingface.co/Qwen/Qwen3-8B-GGUF
spring.ai.ollama.chat.options.model=hf.co/Qwen/Qwen3-8B-GGUF
# https://docs.spring.io/spring-ai/reference/2.0/api/chat/ollama-chat.html#_thinking_mode_reasoning
#spring.ai.ollama.chat.options.think-option=true
spring.ai.ollama.chat.options.temperature=0.6
spring.ai.ollama.chat.options.top-p=0.95
spring.ai.ollama.chat.options.top-k=20
spring.ai.ollama.chat.options.min-p=0
spring.ai.ollama.chat.options.presence-penalty=1.5

# Ollama embedding model
# https://huggingface.co/Qwen/Qwen3-Embedding-8B-GGUF
spring.ai.ollama.embedding.options.model=hf.co/Qwen/Qwen3-Embedding-8B-GGUF

# Ollama auto-pull model configuration
spring.ai.ollama.init.pull-model-strategy=always
spring.ai.ollama.init.timeout=15m
spring.ai.ollama.init.max-retries=2

# A2A blocking timeout configuration
# Increase from default 30s to allow slow LLM responses
a2a.blocking.agent.timeout.seconds=120

